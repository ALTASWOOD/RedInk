# AI服务架构设计

## 文档信息

| 项目 | 内容 |
|------|------|
| 文档版本 | V1.0 |
| 文档状态 | 已完成 |
| 创建日期 | 2026-02-28 |
| 最后更新 | 2026-02-28 |

---

## 1. 概述

### 1.1 设计目标

AI服务架构是 RedInk 的核心模块之一，负责：

- 统一管理多种AI服务的接入
- 实现公网/私域环境的隔离切换
- 提供一致的AI调用接口
- 处理AI服务的容错和降级

### 1.2 核心特性

| 特性 | 说明 |
|------|------|
| 多AI支持 | 支持OpenAI、Claude、国产大模型、本地Ollama等 |
| 环境隔离 | 公网环境与私域环境严格隔离 |
| 统一接口 | 无论使用哪种AI，上层调用接口保持一致 |
| 流式响应 | 支持流式输出，提升用户体验 |
| 故障转移 | 支持自动故障转移和降级策略 |

---

## 2. 架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────────────┐
│                        业务调用层                                    │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │
│  │ 内容生成    │ │ 内容审核    │ │ 内容改写    │ │ 图表生成    │   │
│  └─────────────┘ └─────────────┘ └─────────────┘ └─────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────┐
│                      AI服务管理器 (AIServiceManager)                 │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                    环境管理器 (EnvironmentManager)           │   │
│  │              ┌──────────────┬──────────────┐                │   │
│  │              │   公网环境    │   私域环境    │                │   │
│  │              │   (蓝色)     │   (绿色)     │                │   │
│  │              └──────────────┴──────────────┘                │   │
│  └─────────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                    请求调度器 (RequestDispatcher)            │   │
│  │         负载均衡 | 重试策略 | 超时控制 | 流式处理             │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────┐
│                      AI适配器层 (Adapter Layer)                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                 统一适配器接口 (IAIAdapter)                   │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                    │                                │
│    ┌───────────┬───────────┬───────────┬───────────┬──────────┐   │
│    ▼           ▼           ▼           ▼           ▼          │   │
│ ┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐  │   │
│ │OpenAI │ │Claude │ │ 通义  │ │ 文心  │ │ 星火  │ │Ollama │  │   │
│ │Adapter│ │Adapter│ │Adapter│ │Adapter│ │Adapter│ │Adapter│  │   │
│ └───────┘ └───────┘ └───────┘ └───────┘ └───────┘ └───────┘  │   │
│  (公网)    (公网)    (公网)    (公网)    (公网)    (私域)      │   │
└─────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────┐
│                          网络层                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  HTTPS (公网)                │  HTTP (本地私域)              │   │
│  │  api.openai.com              │  localhost:11434 (Ollama)    │   │
│  │  api.anthropic.com           │  localhost:1234 (LM Studio)  │   │
│  │  dashscope.aliyuncs.com      │  自定义本地服务地址           │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
```

### 2.2 环境隔离机制

```
┌─────────────────────────────────────────────────────────────────┐
│                        环境管理器                                │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │                    当前环境状态                            │ │
│  │  ┌─────────────────────┬─────────────────────┐           │ │
│  │  │    PUBLIC (公网)     │    PRIVATE (私域)   │           │ │
│  │  ├─────────────────────┼─────────────────────┤           │ │
│  │  │ 主题色: 蓝色 #1890FF │ 主题色: 绿色 #52C41A │           │ │
│  │  │ 可用AI: 所有公网AI   │ 可用AI: 仅本地AI    │           │ │
│  │  │ 数据传输: 加密上云   │ 数据传输: 仅本地    │           │ │
│  │  │ 敏感检测: 开启警告   │ 敏感检测: 无需警告  │           │ │
│  │  └─────────────────────┴─────────────────────┘           │ │
│  └───────────────────────────────────────────────────────────┘ │
│                                                                 │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │                    环境切换规则                            │ │
│  │                                                           │ │
│  │  PUBLIC → PRIVATE: 直接切换，无警告                        │ │
│  │  PRIVATE → PUBLIC: 需要二次确认，显示安全警告              │ │
│  │                                                           │ │
│  └───────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

---

## 3. 接口设计

### 3.1 统一AI接口定义

```typescript
/**
 * AI服务统一接口
 */
interface IAIAdapter {
  /** 适配器唯一标识 */
  readonly id: string;
  
  /** 适配器名称 */
  readonly name: string;
  
  /** 所属环境类型 */
  readonly environmentType: 'public' | 'private';
  
  /** 
   * 生成内容
   * @param request 生成请求
   * @returns 生成结果
   */
  generate(request: GenerateRequest): Promise<GenerateResponse>;
  
  /**
   * 流式生成内容
   * @param request 生成请求
   * @param onChunk 分块回调
   */
  generateStream(
    request: GenerateRequest, 
    onChunk: (chunk: string) => void
  ): Promise<void>;
  
  /**
   * 审核内容
   * @param request 审核请求
   * @returns 审核结果
   */
  review(request: ReviewRequest): Promise<ReviewResponse>;
  
  /**
   * 测试连接
   * @returns 连接状态
   */
  testConnection(): Promise<ConnectionStatus>;
}

/**
 * 生成请求
 */
interface GenerateRequest {
  /** 系统提示词 */
  systemPrompt?: string;
  /** 用户输入 */
  userPrompt: string;
  /** 上下文（历史对话） */
  context?: Message[];
  /** 模型参数 */
  options?: ModelOptions;
}

/**
 * 模型参数
 */
interface ModelOptions {
  /** 模型名称 */
  model?: string;
  /** 温度参数 (0-2) */
  temperature?: number;
  /** 最大token数 */
  maxTokens?: number;
  /** Top P 采样 */
  topP?: number;
}

/**
 * 生成响应
 */
interface GenerateResponse {
  /** 生成的内容 */
  content: string;
  /** 使用的token数 */
  usage?: TokenUsage;
  /** 完成原因 */
  finishReason?: 'stop' | 'length' | 'error';
}

/**
 * 审核请求
 */
interface ReviewRequest {
  /** 待审核内容 */
  content: string;
  /** 审核规则 */
  rules?: ReviewRule[];
  /** 审核类型 */
  reviewType: 'content' | 'format' | 'all';
}

/**
 * 审核响应
 */
interface ReviewResponse {
  /** 是否通过 */
  passed: boolean;
  /** 问题列表 */
  issues: ReviewIssue[];
  /** 修改建议 */
  suggestions: string[];
  /** 审核得分 (0-100) */
  score: number;
}
```

### 3.2 AI服务管理器接口

```typescript
/**
 * AI服务管理器
 */
interface IAIServiceManager {
  /**
   * 获取当前环境
   */
  getCurrentEnvironment(): Environment;
  
  /**
   * 切换环境
   * @param env 目标环境
   */
  switchEnvironment(env: 'public' | 'private'): Promise<void>;
  
  /**
   * 获取当前可用的AI适配器列表
   */
  getAvailableAdapters(): IAIAdapter[];
  
  /**
   * 获取当前激活的AI适配器
   */
  getActiveAdapter(): IAIAdapter;
  
  /**
   * 设置激活的AI适配器
   * @param adapterId 适配器ID
   */
  setActiveAdapter(adapterId: string): void;
  
  /**
   * 生成内容（使用当前激活的适配器）
   */
  generate(request: GenerateRequest): Promise<GenerateResponse>;
  
  /**
   * 流式生成内容
   */
  generateStream(
    request: GenerateRequest,
    onChunk: (chunk: string) => void
  ): Promise<void>;
  
  /**
   * 审核内容
   */
  review(request: ReviewRequest): Promise<ReviewResponse>;
}
```

---

## 4. 适配器实现

### 4.1 适配器基类

```typescript
/**
 * AI适配器基类
 */
abstract class BaseAIAdapter implements IAIAdapter {
  abstract readonly id: string;
  abstract readonly name: string;
  abstract readonly environmentType: 'public' | 'private';
  
  protected config: AdapterConfig;
  protected httpClient: AxiosInstance;
  
  constructor(config: AdapterConfig) {
    this.config = config;
    this.httpClient = axios.create({
      baseURL: config.baseUrl,
      timeout: config.timeout || 60000,
      headers: this.getHeaders()
    });
  }
  
  protected abstract getHeaders(): Record<string, string>;
  
  abstract generate(request: GenerateRequest): Promise<GenerateResponse>;
  abstract generateStream(
    request: GenerateRequest,
    onChunk: (chunk: string) => void
  ): Promise<void>;
  
  async review(request: ReviewRequest): Promise<ReviewResponse> {
    // 默认实现：使用生成接口进行审核
    const reviewPrompt = this.buildReviewPrompt(request);
    const response = await this.generate({
      systemPrompt: REVIEW_SYSTEM_PROMPT,
      userPrompt: reviewPrompt
    });
    return this.parseReviewResponse(response.content);
  }
  
  async testConnection(): Promise<ConnectionStatus> {
    try {
      await this.generate({
        userPrompt: 'Hello',
        options: { maxTokens: 10 }
      });
      return { connected: true };
    } catch (error) {
      return { 
        connected: false, 
        error: error.message 
      };
    }
  }
  
  protected buildReviewPrompt(request: ReviewRequest): string {
    // 构建审核提示词...
  }
  
  protected parseReviewResponse(content: string): ReviewResponse {
    // 解析审核响应...
  }
}
```

### 4.2 OpenAI 适配器

```typescript
/**
 * OpenAI API 适配器
 */
class OpenAIAdapter extends BaseAIAdapter {
  readonly id = 'openai';
  readonly name = 'OpenAI GPT';
  readonly environmentType = 'public' as const;
  
  protected getHeaders(): Record<string, string> {
    return {
      'Authorization': `Bearer ${this.config.apiKey}`,
      'Content-Type': 'application/json'
    };
  }
  
  async generate(request: GenerateRequest): Promise<GenerateResponse> {
    const messages = this.buildMessages(request);
    
    const response = await this.httpClient.post('/v1/chat/completions', {
      model: request.options?.model || 'gpt-4',
      messages,
      temperature: request.options?.temperature || 0.7,
      max_tokens: request.options?.maxTokens || 4096
    });
    
    return {
      content: response.data.choices[0].message.content,
      usage: {
        promptTokens: response.data.usage.prompt_tokens,
        completionTokens: response.data.usage.completion_tokens,
        totalTokens: response.data.usage.total_tokens
      },
      finishReason: response.data.choices[0].finish_reason
    };
  }
  
  async generateStream(
    request: GenerateRequest,
    onChunk: (chunk: string) => void
  ): Promise<void> {
    const messages = this.buildMessages(request);
    
    const response = await this.httpClient.post('/v1/chat/completions', {
      model: request.options?.model || 'gpt-4',
      messages,
      temperature: request.options?.temperature || 0.7,
      max_tokens: request.options?.maxTokens || 4096,
      stream: true
    }, {
      responseType: 'stream'
    });
    
    for await (const chunk of response.data) {
      const lines = chunk.toString().split('\n');
      for (const line of lines) {
        if (line.startsWith('data: ') && line !== 'data: [DONE]') {
          const data = JSON.parse(line.slice(6));
          const content = data.choices[0]?.delta?.content;
          if (content) {
            onChunk(content);
          }
        }
      }
    }
  }
  
  private buildMessages(request: GenerateRequest) {
    const messages = [];
    
    if (request.systemPrompt) {
      messages.push({ role: 'system', content: request.systemPrompt });
    }
    
    if (request.context) {
      messages.push(...request.context);
    }
    
    messages.push({ role: 'user', content: request.userPrompt });
    
    return messages;
  }
}
```

### 4.3 Ollama 本地适配器

```typescript
/**
 * Ollama 本地AI适配器
 */
class OllamaAdapter extends BaseAIAdapter {
  readonly id = 'ollama';
  readonly name = 'Ollama 本地AI';
  readonly environmentType = 'private' as const;
  
  constructor(config?: Partial<AdapterConfig>) {
    super({
      baseUrl: config?.baseUrl || 'http://localhost:11434',
      timeout: config?.timeout || 120000,
      ...config
    });
  }
  
  protected getHeaders(): Record<string, string> {
    return {
      'Content-Type': 'application/json'
    };
  }
  
  async generate(request: GenerateRequest): Promise<GenerateResponse> {
    const prompt = this.buildPrompt(request);
    
    const response = await this.httpClient.post('/api/generate', {
      model: request.options?.model || 'qwen:7b',
      prompt,
      stream: false,
      options: {
        temperature: request.options?.temperature || 0.7,
        num_predict: request.options?.maxTokens || 4096
      }
    });
    
    return {
      content: response.data.response,
      finishReason: 'stop'
    };
  }
  
  async generateStream(
    request: GenerateRequest,
    onChunk: (chunk: string) => void
  ): Promise<void> {
    const prompt = this.buildPrompt(request);
    
    const response = await this.httpClient.post('/api/generate', {
      model: request.options?.model || 'qwen:7b',
      prompt,
      stream: true,
      options: {
        temperature: request.options?.temperature || 0.7,
        num_predict: request.options?.maxTokens || 4096
      }
    }, {
      responseType: 'stream'
    });
    
    for await (const chunk of response.data) {
      const data = JSON.parse(chunk.toString());
      if (data.response) {
        onChunk(data.response);
      }
    }
  }
  
  /**
   * 获取可用模型列表
   */
  async listModels(): Promise<string[]> {
    const response = await this.httpClient.get('/api/tags');
    return response.data.models.map((m: any) => m.name);
  }
  
  private buildPrompt(request: GenerateRequest): string {
    let prompt = '';
    
    if (request.systemPrompt) {
      prompt += `系统指令：${request.systemPrompt}\n\n`;
    }
    
    if (request.context) {
      for (const msg of request.context) {
        const role = msg.role === 'user' ? '用户' : 'AI';
        prompt += `${role}：${msg.content}\n`;
      }
    }
    
    prompt += `用户：${request.userPrompt}\nAI：`;
    
    return prompt;
  }
}
```

### 4.4 通义千问适配器

```typescript
/**
 * 通义千问 API 适配器
 */
class QwenAdapter extends BaseAIAdapter {
  readonly id = 'qwen';
  readonly name = '通义千问';
  readonly environmentType = 'public' as const;
  
  constructor(config: AdapterConfig) {
    super({
      ...config,
      baseUrl: 'https://dashscope.aliyuncs.com/api/v1'
    });
  }
  
  protected getHeaders(): Record<string, string> {
    return {
      'Authorization': `Bearer ${this.config.apiKey}`,
      'Content-Type': 'application/json'
    };
  }
  
  async generate(request: GenerateRequest): Promise<GenerateResponse> {
    const messages = this.buildMessages(request);
    
    const response = await this.httpClient.post('/services/aigc/text-generation/generation', {
      model: request.options?.model || 'qwen-turbo',
      input: { messages },
      parameters: {
        temperature: request.options?.temperature || 0.7,
        max_tokens: request.options?.maxTokens || 4096,
        result_format: 'message'
      }
    });
    
    return {
      content: response.data.output.choices[0].message.content,
      usage: {
        promptTokens: response.data.usage.input_tokens,
        completionTokens: response.data.usage.output_tokens,
        totalTokens: response.data.usage.input_tokens + response.data.usage.output_tokens
      },
      finishReason: 'stop'
    };
  }
  
  async generateStream(
    request: GenerateRequest,
    onChunk: (chunk: string) => void
  ): Promise<void> {
    const messages = this.buildMessages(request);
    
    const response = await this.httpClient.post('/services/aigc/text-generation/generation', {
      model: request.options?.model || 'qwen-turbo',
      input: { messages },
      parameters: {
        temperature: request.options?.temperature || 0.7,
        max_tokens: request.options?.maxTokens || 4096,
        result_format: 'message',
        incremental_output: true
      }
    }, {
      headers: {
        ...this.getHeaders(),
        'X-DashScope-SSE': 'enable'
      },
      responseType: 'stream'
    });
    
    for await (const chunk of response.data) {
      const lines = chunk.toString().split('\n');
      for (const line of lines) {
        if (line.startsWith('data:')) {
          const data = JSON.parse(line.slice(5));
          const content = data.output?.choices?.[0]?.message?.content;
          if (content) {
            onChunk(content);
          }
        }
      }
    }
  }
  
  private buildMessages(request: GenerateRequest) {
    const messages = [];
    
    if (request.systemPrompt) {
      messages.push({ role: 'system', content: request.systemPrompt });
    }
    
    if (request.context) {
      messages.push(...request.context);
    }
    
    messages.push({ role: 'user', content: request.userPrompt });
    
    return messages;
  }
}
```

---

## 5. 服务管理器实现

### 5.1 环境管理器

```typescript
/**
 * 环境类型
 */
type EnvironmentType = 'public' | 'private';

/**
 * 环境配置
 */
interface Environment {
  type: EnvironmentType;
  themeColor: string;
  label: string;
  description: string;
}

/**
 * 环境定义
 */
const ENVIRONMENTS: Record<EnvironmentType, Environment> = {
  public: {
    type: 'public',
    themeColor: '#1890FF',
    label: '公网环境',
    description: '使用云端AI服务，数据将通过网络传输'
  },
  private: {
    type: 'private',
    themeColor: '#52C41A',
    label: '私域环境',
    description: '使用本地AI服务，数据完全本地处理'
  }
};

/**
 * 环境管理器
 */
class EnvironmentManager {
  private currentEnv: EnvironmentType = 'private'; // 默认私域环境
  private listeners: Set<(env: Environment) => void> = new Set();
  
  /**
   * 获取当前环境
   */
  getCurrentEnvironment(): Environment {
    return ENVIRONMENTS[this.currentEnv];
  }
  
  /**
   * 切换环境
   */
  async switchEnvironment(targetEnv: EnvironmentType): Promise<void> {
    if (this.currentEnv === targetEnv) return;
    
    // 从私域切换到公网需要确认
    if (this.currentEnv === 'private' && targetEnv === 'public') {
      const confirmed = await this.showSwitchWarning();
      if (!confirmed) {
        throw new Error('用户取消切换');
      }
    }
    
    this.currentEnv = targetEnv;
    this.notifyListeners();
  }
  
  /**
   * 显示切换警告
   */
  private async showSwitchWarning(): Promise<boolean> {
    // 由UI层实现确认对话框
    return new Promise((resolve) => {
      // 发送事件给UI层处理
      window.dispatchEvent(new CustomEvent('env-switch-confirm', {
        detail: {
          resolve,
          message: '切换到公网环境可能导致数据上传至云端，请确认当前文档不含敏感信息'
        }
      }));
    });
  }
  
  /**
   * 订阅环境变化
   */
  subscribe(listener: (env: Environment) => void): () => void {
    this.listeners.add(listener);
    return () => this.listeners.delete(listener);
  }
  
  private notifyListeners(): void {
    const env = this.getCurrentEnvironment();
    this.listeners.forEach(listener => listener(env));
  }
}
```

### 5.2 AI服务管理器

```typescript
/**
 * AI服务管理器实现
 */
class AIServiceManager implements IAIServiceManager {
  private envManager: EnvironmentManager;
  private adapters: Map<string, IAIAdapter> = new Map();
  private activeAdapterId: string | null = null;
  
  constructor() {
    this.envManager = new EnvironmentManager();
    this.initializeAdapters();
    
    // 环境切换时重新选择适配器
    this.envManager.subscribe(() => {
      this.autoSelectAdapter();
    });
  }
  
  /**
   * 初始化所有适配器
   */
  private initializeAdapters(): void {
    // 公网适配器
    const openaiConfig = this.loadConfig('openai');
    if (openaiConfig?.apiKey) {
      this.adapters.set('openai', new OpenAIAdapter(openaiConfig));
    }
    
    const qwenConfig = this.loadConfig('qwen');
    if (qwenConfig?.apiKey) {
      this.adapters.set('qwen', new QwenAdapter(qwenConfig));
    }
    
    // 私域适配器（Ollama默认可用）
    this.adapters.set('ollama', new OllamaAdapter());
    
    // 自动选择默认适配器
    this.autoSelectAdapter();
  }
  
  /**
   * 根据环境自动选择适配器
   */
  private autoSelectAdapter(): void {
    const env = this.envManager.getCurrentEnvironment();
    const available = this.getAvailableAdapters();
    
    if (available.length > 0) {
      // 优先选择与当前环境匹配的适配器
      const preferred = available.find(a => a.environmentType === env.type);
      this.activeAdapterId = preferred?.id || available[0].id;
    }
  }
  
  getCurrentEnvironment(): Environment {
    return this.envManager.getCurrentEnvironment();
  }
  
  async switchEnvironment(env: 'public' | 'private'): Promise<void> {
    await this.envManager.switchEnvironment(env);
  }
  
  getAvailableAdapters(): IAIAdapter[] {
    const env = this.envManager.getCurrentEnvironment();
    
    return Array.from(this.adapters.values()).filter(adapter => {
      // 私域环境只显示私域适配器
      if (env.type === 'private') {
        return adapter.environmentType === 'private';
      }
      // 公网环境显示所有适配器
      return true;
    });
  }
  
  getActiveAdapter(): IAIAdapter {
    if (!this.activeAdapterId) {
      throw new Error('没有可用的AI适配器');
    }
    const adapter = this.adapters.get(this.activeAdapterId);
    if (!adapter) {
      throw new Error('AI适配器不存在');
    }
    return adapter;
  }
  
  setActiveAdapter(adapterId: string): void {
    const adapter = this.adapters.get(adapterId);
    if (!adapter) {
      throw new Error('AI适配器不存在');
    }
    
    const env = this.envManager.getCurrentEnvironment();
    
    // 私域环境不允许选择公网适配器
    if (env.type === 'private' && adapter.environmentType === 'public') {
      throw new Error('私域环境下不能使用公网AI服务');
    }
    
    this.activeAdapterId = adapterId;
  }
  
  async generate(request: GenerateRequest): Promise<GenerateResponse> {
    const adapter = this.getActiveAdapter();
    
    // 公网环境下检查敏感信息
    const env = this.envManager.getCurrentEnvironment();
    if (env.type === 'public') {
      this.checkSensitiveContent(request.userPrompt);
    }
    
    return adapter.generate(request);
  }
  
  async generateStream(
    request: GenerateRequest,
    onChunk: (chunk: string) => void
  ): Promise<void> {
    const adapter = this.getActiveAdapter();
    
    const env = this.envManager.getCurrentEnvironment();
    if (env.type === 'public') {
      this.checkSensitiveContent(request.userPrompt);
    }
    
    return adapter.generateStream(request, onChunk);
  }
  
  async review(request: ReviewRequest): Promise<ReviewResponse> {
    const adapter = this.getActiveAdapter();
    return adapter.review(request);
  }
  
  /**
   * 检查敏感内容
   */
  private checkSensitiveContent(content: string): void {
    const sensitivePatterns = [
      /\d{18}|\d{15}/g,                    // 身份证号
      /1[3-9]\d{9}/g,                       // 手机号
      /\d{16,19}/g,                         // 银行卡号
      /密级|机密|绝密|内部/g,               // 涉密关键词
    ];
    
    for (const pattern of sensitivePatterns) {
      if (pattern.test(content)) {
        // 发送警告事件
        window.dispatchEvent(new CustomEvent('sensitive-content-warning', {
          detail: { content, pattern: pattern.source }
        }));
        break;
      }
    }
  }
  
  private loadConfig(adapterId: string): AdapterConfig | null {
    // 从本地存储加载配置
    const configStr = localStorage.getItem(`ai_config_${adapterId}`);
    return configStr ? JSON.parse(configStr) : null;
  }
}

// 导出单例
export const aiService = new AIServiceManager();
```

---

## 6. 错误处理与容错

### 6.1 错误类型定义

```typescript
/**
 * AI服务错误基类
 */
class AIServiceError extends Error {
  constructor(
    message: string,
    public readonly code: string,
    public readonly adapterId: string
  ) {
    super(message);
    this.name = 'AIServiceError';
  }
}

/**
 * 网络错误
 */
class NetworkError extends AIServiceError {
  constructor(adapterId: string, originalError: Error) {
    super(
      `网络连接失败: ${originalError.message}`,
      'NETWORK_ERROR',
      adapterId
    );
  }
}

/**
 * 认证错误
 */
class AuthenticationError extends AIServiceError {
  constructor(adapterId: string) {
    super('API密钥无效或已过期', 'AUTH_ERROR', adapterId);
  }
}

/**
 * 配额超限错误
 */
class QuotaExceededError extends AIServiceError {
  constructor(adapterId: string) {
    super('API调用配额已用尽', 'QUOTA_EXCEEDED', adapterId);
  }
}

/**
 * 模型不可用错误
 */
class ModelUnavailableError extends AIServiceError {
  constructor(adapterId: string, model: string) {
    super(`模型 ${model} 不可用`, 'MODEL_UNAVAILABLE', adapterId);
  }
}
```

### 6.2 重试策略

```typescript
/**
 * 重试配置
 */
interface RetryConfig {
  maxRetries: number;
  baseDelay: number;
  maxDelay: number;
  retryableErrors: string[];
}

/**
 * 默认重试配置
 */
const DEFAULT_RETRY_CONFIG: RetryConfig = {
  maxRetries: 3,
  baseDelay: 1000,
  maxDelay: 10000,
  retryableErrors: ['NETWORK_ERROR', 'RATE_LIMITED']
};

/**
 * 带重试的请求包装器
 */
async function withRetry<T>(
  fn: () => Promise<T>,
  config: RetryConfig = DEFAULT_RETRY_CONFIG
): Promise<T> {
  let lastError: Error;
  
  for (let attempt = 0; attempt <= config.maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;
      
      // 检查是否可重试
      if (error instanceof AIServiceError) {
        if (!config.retryableErrors.includes(error.code)) {
          throw error;
        }
      }
      
      // 最后一次尝试失败，抛出错误
      if (attempt === config.maxRetries) {
        throw error;
      }
      
      // 计算延迟时间（指数退避）
      const delay = Math.min(
        config.baseDelay * Math.pow(2, attempt),
        config.maxDelay
      );
      
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw lastError!;
}
```

---

## 7. 提示词管理

### 7.1 系统提示词模板

```typescript
/**
 * 公文生成系统提示词
 */
const DOCUMENT_GENERATION_PROMPT = `你是一个专业的公文写作助手。请根据用户提供的要点，生成符合规范的公文内容。

要求：
1. 语言正式、准确、简洁
2. 结构清晰，逻辑严密
3. 符合党政机关公文格式规范
4. 避免口语化表达

输出格式：直接输出公文内容，不要添加额外解释。`;

/**
 * 公文审核系统提示词
 */
const DOCUMENT_REVIEW_PROMPT = `你是一个专业的公文审核专家。请对用户提供的公文内容进行全面审核。

审核要点：
1. 格式规范性：标题、正文、落款等是否符合规范
2. 内容准确性：数据、日期、称谓等是否准确
3. 逻辑严密性：论述是否有逻辑、前后是否一致
4. 语言规范性：用词是否恰当、是否有语病
5. 政策合规性：内容是否符合相关政策法规

请以JSON格式输出审核结果：
{
  "passed": boolean,
  "score": number (0-100),
  "issues": [
    { "type": "格式/内容/逻辑/语言/政策", "description": "问题描述", "position": "问题位置", "suggestion": "修改建议" }
  ],
  "summary": "总体评价"
}`;

/**
 * 内容改写系统提示词
 */
const CONTENT_REWRITE_PROMPT = `你是一个专业的文字润色专家。请根据用户的要求改写提供的内容。

改写原则：
1. 保持原意不变
2. 提升文字表达质量
3. 符合公文语言风格
4. 注意用词准确性

直接输出改写后的内容。`;
```

### 7.2 提示词管理器

```typescript
/**
 * 提示词类型
 */
type PromptType = 
  | 'document_generation'
  | 'document_review'
  | 'content_rewrite'
  | 'chart_generation';

/**
 * 提示词管理器
 */
class PromptManager {
  private prompts: Map<PromptType, string> = new Map([
    ['document_generation', DOCUMENT_GENERATION_PROMPT],
    ['document_review', DOCUMENT_REVIEW_PROMPT],
    ['content_rewrite', CONTENT_REWRITE_PROMPT],
  ]);
  
  /**
   * 获取系统提示词
   */
  getSystemPrompt(type: PromptType): string {
    const prompt = this.prompts.get(type);
    if (!prompt) {
      throw new Error(`未知的提示词类型: ${type}`);
    }
    return prompt;
  }
  
  /**
   * 自定义提示词（用户可覆盖）
   */
  setCustomPrompt(type: PromptType, prompt: string): void {
    this.prompts.set(type, prompt);
    // 持久化存储
    localStorage.setItem(`custom_prompt_${type}`, prompt);
  }
  
  /**
   * 重置为默认提示词
   */
  resetToDefault(type: PromptType): void {
    localStorage.removeItem(`custom_prompt_${type}`);
    // 重新加载默认提示词
    this.loadDefaultPrompts();
  }
  
  private loadDefaultPrompts(): void {
    // 加载默认提示词...
  }
}
```

---

## 8. 配置管理

### 8.1 AI配置界面数据结构

```typescript
/**
 * AI服务配置
 */
interface AIConfig {
  /** 公网AI配置 */
  publicAI: {
    /** 当前选择的提供商 */
    provider: 'openai' | 'claude' | 'qwen' | 'wenxin' | 'spark';
    /** 各提供商配置 */
    providers: {
      openai?: OpenAIConfig;
      claude?: ClaudeConfig;
      qwen?: QwenConfig;
      wenxin?: WenxinConfig;
      spark?: SparkConfig;
    };
  };
  
  /** 私域AI配置 */
  privateAI: {
    /** 服务类型 */
    type: 'ollama' | 'lmstudio' | 'custom';
    /** Ollama配置 */
    ollama?: OllamaConfig;
    /** LM Studio配置 */
    lmstudio?: LMStudioConfig;
    /** 自定义服务配置 */
    custom?: CustomAIConfig;
  };
  
  /** 默认环境 */
  defaultEnvironment: 'public' | 'private';
  
  /** 敏感信息检测开关 */
  sensitiveDetectionEnabled: boolean;
}

/**
 * OpenAI配置
 */
interface OpenAIConfig {
  apiKey: string;
  baseUrl?: string;  // 自定义API地址（用于代理）
  model: string;     // 默认模型
  temperature: number;
  maxTokens: number;
}

/**
 * Ollama配置
 */
interface OllamaConfig {
  baseUrl: string;   // 默认 http://localhost:11434
  model: string;     // 默认模型
  temperature: number;
  maxTokens: number;
}
```

---

## 9. 附录

### 9.1 支持的AI服务列表

| 服务商 | 环境 | 模型 | 说明 |
|--------|------|------|------|
| OpenAI | 公网 | GPT-4, GPT-3.5 | 国际主流 |
| Claude | 公网 | Claude-3 | 长文本能力强 |
| 通义千问 | 公网 | qwen-turbo, qwen-plus | 阿里云 |
| 文心一言 | 公网 | ERNIE-Bot | 百度云 |
| 讯飞星火 | 公网 | Spark | 科大讯飞 |
| Ollama | 私域 | Qwen, Llama, ChatGLM | 本地部署 |
| LM Studio | 私域 | 各种GGUF模型 | 本地部署 |

### 9.2 推荐本地模型

| 模型 | 参数量 | 内存要求 | 推荐场景 |
|------|--------|----------|----------|
| Qwen-7B-Chat | 7B | 8GB+ | 通用场景 |
| ChatGLM3-6B | 6B | 8GB+ | 中文对话 |
| Llama-2-7B-Chat | 7B | 8GB+ | 通用场景 |
| Qwen-14B-Chat | 14B | 16GB+ | 高质量生成 |
| Yi-34B-Chat | 34B | 32GB+ | 最高质量 |

---

*文档结束*
